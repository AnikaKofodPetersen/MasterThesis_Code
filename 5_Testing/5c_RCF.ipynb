{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62cc0946",
   "metadata": {},
   "source": [
    "# Finetune a multitask model on concatenated embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5113edd3",
   "metadata": {},
   "source": [
    "This notebook aims at concatenating the ESM and PS embeddings and perform RCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d02fc",
   "metadata": {},
   "source": [
    "### Import and initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21595bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Import stuff\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sn\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import linregress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60127e3",
   "metadata": {},
   "source": [
    "### Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd63ff7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Only use cpu\n",
    "device = \"cpu\"\n",
    "\n",
    "#Assign embedding folder\n",
    "ESM_EMB_PATH = \"../4_FineTuning//PCA_reduced/ESM_embeddings/\"\n",
    "PS_EMB_PATH = \"../4_FineTuning//PCA_reduced/PS_embeddings/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17dc1de",
   "metadata": {},
   "source": [
    "## Load experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5188d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load experimental values\n",
    "exp = pd.read_csv(\"../4_FineTuning/jain_full.csv\", sep=\";\")\n",
    "exp.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186fc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02efa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize AC-SINS\n",
    "norm_ac = [(data - min(exp[\"AC-SINS\"])) / (max(exp[\"AC-SINS\"]) - min(exp[\"AC-SINS\"])) for data in exp[\"AC-SINS\"]]\n",
    "exp[\"norm_AC-SINS\"] = norm_ac\n",
    "\n",
    "#Normalize HIC\n",
    "norm_hic = [(data - min(exp[\"HIC\"])) / (max(exp[\"HIC\"]) - min(exp[\"HIC\"])) for data in exp[\"HIC\"]]\n",
    "exp[\"norm_HIC\"] = norm_hic\n",
    "\n",
    "#Add fake labels for testing\n",
    "rng = np.random.default_rng(12345)\n",
    "rand = rng.random(len(norm_ac))\n",
    "exp[\"fake\"] = rand\n",
    "\n",
    "#Binary classifictaion\n",
    "bc = [0 if val <= 5 else 1 for val in exp[\"AC-SINS\"]]\n",
    "exp[\"BC\"] = bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f374d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b8bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp[\"Name.1\"]\n",
    "del exp[\"match\"]\n",
    "del exp[\"fake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c6782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sequences from fasta file\n",
    "fastas = {}\n",
    "with open(\"../4_FineTuning//antibody_bulk.fsa\", \"r\") as fasta:\n",
    "    for line in fasta:\n",
    "        if line.startswith(\">\"):\n",
    "            header = line.strip()[1:]\n",
    "        else:\n",
    "            seq = line.strip()\n",
    "            fastas[header] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9254080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that calculates amino acid distribution\n",
    "def aa_dist(seq):\n",
    "    counter = Counter(seq)\n",
    "    aas = [\"A\",\"R\",\"N\",\"D\",\"B\",\"C\",\"Q\",\"E\",\"G\",\"H\",\"I\",\"L\",\"K\",\"M\",\"F\",\"P\",\"S\",\"T\",\"W\",\"V\"]\n",
    "    dist = []\n",
    "    for aa in aas:\n",
    "        if aa in counter:\n",
    "            dist.append(counter[aa]/len(seq))\n",
    "        else:\n",
    "            dist.append(0)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect sequences and aa distribution\n",
    "seqs =  []\n",
    "dists = []\n",
    "for i, row in exp.iterrows():\n",
    "    name = row[\"Name\"]\n",
    "    seq = fastas[name]\n",
    "    seqs.append(seq)\n",
    "    dists.append(aa_dist(fastas[name]))\n",
    "    \n",
    "#Add to dataframe\n",
    "aadf = pd.DataFrame(dists, columns = [\"A\",\"R\",\"N\",\"D\",\"B\",\"C\",\"Q\",\"E\",\"G\",\"H\",\"I\",\"L\",\"K\",\"M\",\"F\",\"P\",\"S\",\"T\",\"W\",\"V\"])\n",
    "exp[\"Sequence\"] = seqs\n",
    "exp = pd.concat([exp, aadf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff668269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make bc dict\n",
    "label_dict = {}\n",
    "for i, row in exp.iterrows():\n",
    "    label_dict[row[\"Name\"]] = row[\"BC\"]\n",
    "    \n",
    "print(len(label_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56937df0",
   "metadata": {},
   "source": [
    "### Load ESM embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db226084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and format embeddings in a dict\n",
    "ESM_embs_dict = dict()     \n",
    "for file in os.listdir(ESM_EMB_PATH):\n",
    "    name = file.split(\".\")[0].split(\"_\")[-1]\n",
    "    if file.endswith(\".pt\"):\n",
    "        print (f\"working with file: {file}\", end=\"\\r\")\n",
    "        tensor_in = torch.load(f'{ESM_EMB_PATH}/{file}')\n",
    "        ESM_embs_dict[name] = tensor_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda86ee",
   "metadata": {},
   "source": [
    "### Load PS embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and format embeddings\n",
    "PS_embs_dict = dict()\n",
    "for file in os.listdir(PS_EMB_PATH):\n",
    "    name = file.split(\".\")[0].split(\"_\")[-1]\n",
    "    if file.endswith(\".pt\"):\n",
    "        print (f\"working with file: {file}\", end=\"\\r\")\n",
    "        tensor_in = torch.load(f'{PS_EMB_PATH}/{file}')\n",
    "        PS_embs_dict[name] = tensor_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d0a07",
   "metadata": {},
   "source": [
    "### Concatenate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate PS and ESm embeddings\n",
    "cat_embs_dict = dict()\n",
    "count = 0\n",
    "\n",
    "# Iterate through sequence embeddings\n",
    "for key, value in ESM_embs_dict.items():\n",
    "    count += 1\n",
    "    print(f\"Working with {count}/{len(ESM_embs_dict)}\", end = \"\\r\")\n",
    "    \n",
    "    #if structure embeddings exist - use it , else use zeros\n",
    "    esm = value\n",
    "    ps = PS_embs_dict[key]\n",
    "\n",
    "    #Sanity check dimensions\n",
    "    assert esm.shape == ps.shape\n",
    "        \n",
    "    #Concatenate the embeddings and add to dict\n",
    "    Xs = torch.cat((esm,ps),1)\n",
    "    cat_embs_dict[key] = Xs\n",
    "\n",
    "print(f\"Concatenated embeddings from {len(cat_embs_dict)} proteins\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f468f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6835616e",
   "metadata": {},
   "source": [
    "### Load sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sequences from fasta file\n",
    "fastas = {}\n",
    "with open(\"../4_FineTuning//antibody_bulk.fsa\", \"r\") as fasta:\n",
    "    for line in fasta:\n",
    "        if line.startswith(\">\"):\n",
    "            header = line.strip()[1:]\n",
    "        else:\n",
    "            seq = line.strip()\n",
    "            fastas[header] = seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047bb47",
   "metadata": {},
   "source": [
    "### Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83101d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that calculates amino acid distribution\n",
    "def aa_dist(seq):\n",
    "    counter = Counter(seq)\n",
    "    aas = [\"A\",\"R\",\"N\",\"D\",\"B\",\"C\",\"Q\",\"E\",\"G\",\"H\",\"I\",\"L\",\"K\",\"M\",\"F\",\"P\",\"S\",\"T\",\"W\",\"V\"]\n",
    "    dist = []\n",
    "    for aa in aas:\n",
    "        if aa in counter:\n",
    "            dist.append(counter[aa]/len(seq))\n",
    "        else:\n",
    "            dist.append(0)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7043d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure dimensions/info in embeddings\n",
    "embs_X = []\n",
    "data_names = {}\n",
    "data_nums = []\n",
    "data_labels = []\n",
    "count = 0\n",
    "for key,embs in cat_embs_dict.items():\n",
    "    count += 1\n",
    "    data_names[count] = key\n",
    "    data_nums.append(torch.tensor(count))\n",
    "    \n",
    "    #Also, add in the extra info\n",
    "    template = [0] * len(embs)\n",
    "    extra = aa_dist(fastas[key])\n",
    "    extra_inf = extra + [len(fastas[key])]\n",
    "    template = [extra_inf for x in template]\n",
    "    extra_inf = torch.FloatTensor(template)\n",
    "    \n",
    "    #Get proper labels\n",
    "    if key in list(exp[\"Name\"]):\n",
    "        data_labels.append(label_dict[key])\n",
    "    \n",
    "        #Append all\n",
    "        embs_X.append(torch.cat((embs,extra_inf), 1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ea567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad the embeddings\n",
    "padded_embs = []\n",
    "for emb in embs_X:\n",
    "    shape = np.shape(emb)\n",
    "    padded_array = np.zeros((500,81))\n",
    "    padded_array[:shape[0],:shape[1]] = emb\n",
    "    flat_array = padded_array.flatten()\n",
    "    padded_embs.append(flat_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c43654",
   "metadata": {},
   "source": [
    "### Dataset, data split and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_embs, data_labels, test_size=0.3, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(X_train)}\\nTest size: {len(X_test)}\")\n",
    "print(f\"Train labels {Counter([label for label in y_train])}\")\n",
    "#print(f\"Validation labels {Counter([label[0] for label in y_val])}\")\n",
    "print(f\"Test labels {Counter([label for label in y_test])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf7c064",
   "metadata": {},
   "source": [
    "### Train the RFC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "AUC = []\n",
    "MCC = []\n",
    "for i in range(2000):\n",
    "    print(i, end=\"\\r\")\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    mcc_running = matthews_corrcoef(y_test, y_pred)\n",
    "    auc_running = roc_auc_score(y_test, y_pred)\n",
    "    AUC.append(auc_running)\n",
    "    MCC.append(mcc_running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db602834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "#Make plot\n",
    "plt.rcParams['figure.figsize'] = [35, 20]   \n",
    "plt.rcParams['font.size']=30\n",
    "\n",
    "densityx = stats.gaussian_kde(MCC)\n",
    "n, x, _ = plt.hist(MCC, bins=np.linspace(-0.4, 0.8, 50), \n",
    "                   histtype=u'step', density=True, lw=5, label=\"MCC histogram\", color = \"blue\")  \n",
    "densityy = stats.gaussian_kde(AUC)\n",
    "n, y, _ = plt.hist(AUC, bins=np.linspace(-0.4, 0.8, 50), \n",
    "                   histtype=u'step', density=True, lw = 5, label=\"AUC histogram\", color = \"red\")  \n",
    "plt.plot(x,densityx(x), lw = 5, label=\"MCC probability density function\", c = \"cornflowerblue\")\n",
    "plt.plot(y, densityy(y), lw = 5, label=\"AUC probability density function\", c = \"coral\")\n",
    "plt.grid()\n",
    "plt.xticks(np.arange(-0.4, 0.81, step=0.1))\n",
    "plt.title(\"Performance of 2000 Random Forest Classifiers \", fontsize = 40)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(\"RFCL_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if this outperforms LSTM model\n",
    "above_MCC = [x for x in MCC if x>=0.4]\n",
    "above_AUC = [x for x in AUC if x>=0.7]\n",
    "print(f\"MCC >= 0.4: {(len(above_MCC)/len(MCC))*100}%\")\n",
    "print(f\"AUC >= 0.7: {(len(above_AUC)/len(AUC))*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f5605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
